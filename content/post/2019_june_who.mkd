R has vast collection of packages and its no wonder that everyday newer and newer tools are coming up. Today I will blog on an wonderful tool to collect data from PDF files. This is called pdftools and it is just great. There are other packages such as "Tabulizer", tabulizer is heavily dependent on Java. Sometimes it is quite cumbersome to work with Java and particularly integration with R. I had some terrible time with XLSconnect which depended on Java. I am still struggling to make tabulizer work in my arch linux installation. Therefore PDFTools is a welcome relief and alternative in the realm of the PDF extraction. 


We issue usual commands to install a library 

Let's first load the required libraries 


```{r}
library(pdftools)
library(glue)
library(tidyverse)
```

Let's first write down the country codes 

```{r}
country <- c("bgd", "ind", "pak", "lka")
```

Let's put the down the url 

```{r}
url  <- "https://www.who.int/diabetes/country-profiles/{country}_en.pdf?ua=1"
```

Now let's glue the urls 


```{r}
urls  <- glue(url)
```

Now I create name of the pdf files in the same manner 


```{r}
pdf_names <- glue("report{country}.pdf")
```

Now let's download the files. Now before doing that I have changed the working directory to Desktop/Downloaded, so reports are actually there 

```{r}
walk2(urls,pdf_names, download.file, mode="wb")
```


Now let's import the data from each file 

```{r}
raw_text <- map(pdf_names, pdf_text)
```

Let's look int the very first element

```{r}
raw_text[1]
```

Now let's try to understand the following code line by line 

```{r}

clean_table  <- function(table){
table  <- str_split(table,"\n", simplify=TRUE)
country_name  <- table[1,1] %>% 
                    str_squish() %>% 
		    str_extract(".+?(?=\\sTotal)")
                     
table_start  <-  str_which(table,"Prevalence of diabetes")
table_end <-  str_which(table,"National response to diabetes")
table <- table[1, (table_start+1):(table_end-1)]
table <- str_replace_all(table, "%", "")
table.dat <- str_split_fixed(table, "[\\s]{2,}", n=4) %>% 
                               as.data.frame() %>% 
			       slice(-1)
names(table.dat)  <- c("Condition", "Males", "Females", "Total")
table.dat %>% 
    mutate(Country=country_name) %>% 
    select(Country, everything()) %>% 
    mutate_at(vars(-c(Country,Condition)), function(x) as.numeric(as.character(x)))
}
```

Now the orginal raw_text[1] was containing a long character vector with line breaks in the middle `\n`. 

So the following code 

```{r}
table  <- str_split(table,"\n", simplify=TRUE)
```

converts the above into a matrix of dimenion (1, 59) in the case of Bangladesh, the very first component. 
Now let's apply this to the original raw_text, the following commands first picked up the country name, then found the string number from where the table started and ended, extracted those location, converted the text into a matrix, then data frame etc etc.

Now we are actually applyingg that function to each element of raw_text

```{r}
health.risk.sa <- map_df(raw_text, clean_table) %>% 
               gather(Sex, Share, Males, Females, Total) %>% 
	       arrange(Country)
save(health.risk.sa, file="./RDATA/health_risk_sa.rda")
```


Now let's plot

```{r}
diabetes %>% 
    filter(Sex=="Total") %>% 
    ggplot() +
       geom_bar(aes(x=Sex, y=Share, fill=Country), stat="identity", position="dodge") + 
       coord_flip()  +
       facet_wrap(~Condition) +
       theme_economist_white() +
       scale_fill_economist()
       
```




